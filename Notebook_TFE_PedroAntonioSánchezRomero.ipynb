{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40630c86",
   "metadata": {},
   "source": [
    "# Introducción \n",
    "\n",
    "En este notebook voy a documentar el proceso de desarrollo del proyecto en cuanto a código se refiere. Nuestra intención es lograr que un vehiculo equipado con una Raspberry Pi 3 sea capaz de seguir una trazada autónomamente. \n",
    "Para lograr esto, primeramente se han recogido muestras de la trazada con la webcam que incluye este vehiculo.\n",
    "Estas muestras van a pasar por un preprocesamiento previo para reducir las componentes, para más tarde usar estas componentes en una red neuronal multicapa o MLP. \n",
    "\n",
    "\n",
    "# Preprocesado\n",
    "\n",
    "En esta sección nuestra intención es la de preparar los datos de entrada a la red con el fin de hacerlos lo más sencillos posible de procesar por nuestra red. Esto se traducirá en una binarización de la imagen, aislando de esta manera la información útil, es decir, la trazada a seguir.\n",
    "Para este caso, se han tomado imágenes con una webcam conectada al vehiculo, que nos proporciona capturas de 640 de ancho y 480 de alto. Esto nos daría un total de 921600 entradas a la red, excesivo en cualquier caso.\n",
    "Dado que el número de datos de entrenamiento aumenta con el número de entradas, necesitaríamos una cantidad inmensa de muestras, con todo lo que eso conlleva: elevado tiempo de cómputo, red compleja, etc.\n",
    "Por lo mencionado anteriormente, el preprocesado de los datos de entrada es de carácter obligatorio.\n",
    "Las imágenes usadas se componen de un fondo gris con la línea azul a seguir, como se muestra en este ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac37318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "921600 import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('imagen_2021-02-16 14_47_49.661111_EjeIzda1_-0.762908935546875_EjeDcha4_-0.979400634765625.jpg')\n",
    "cv2.imshow('Imagen Original', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53463445",
   "metadata": {},
   "source": [
    "Como se puede apreciar, hay una gran cantidad de píxeles que no aportan apenas información pero sí que obstaculizan el entrenamiento.\n",
    "Estas imágenes pasaran por una serie de procesos hasta obtener una imagen binarizada, redimensionada y normalizada.\n",
    "Se ha usado un dataset de 6312 imágenes, suficientes para producir un bajo error. \n",
    "\n",
    "### Desarrollo del código\n",
    "\n",
    "En un fichero llamado preprocesar.py se ha diseñado un código simple pero que ejecuta a la perfección esta necesidad.\n",
    "En primer lugar, importamos los paquetes necesarios, estos son: *os*, *cv2*, *numpy* y *re*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f50de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547a404",
   "metadata": {},
   "source": [
    "La idea es la de \"muestrear\" la imagen y convertirla en un vector fila con todos los valores de los pixeles finales. Para ello se crean las variables usadas como índices del array que contendrá dichos valores. A continuación, se recupera el número de imágenes disponibles en el directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_x = 0\n",
    "indice_y = 0\n",
    "\n",
    "dir = 'D:/imagenes'\n",
    "\n",
    "path, dirs, files = next(os.walk(dir))\n",
    "file_count = len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999ceed",
   "metadata": {},
   "source": [
    "\"Escaneamos\" el directorio en busca de las imágenes, que renombramos como *imagenes*. Creamos una matriz vacía en la que guardaremos los valores de los pixeles seleccionados. Como se puede observar, tiene tantas filas como elementos en el directorio y tantas columnas como número total de puntos que queramos o dicho de otra manera, el número final de píxeles a los que reduciremos la imagen añadiendole dos columnas extra, dedicadas a los valores de salida para ese conjunto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3632f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with os.scandir(dir) as imagenes:\n",
    "    valores = np.empty((file_count, 24 * 18 + 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c702d5f",
   "metadata": {},
   "source": [
    "Prosigue el bucle principal, donde se van a realizar las operaciones. \n",
    "Para poner en contexto, los archivos estan nombrados de manera que aparezca la fecha y hora de la toma, así como los valores que tenían los joysticks del mando. Será necesario extraer estos últimos dos valores, pues se tratan de nuestras salidas.\n",
    "Sabiendo esto, se ha usado una *expresion regular*. Para este caso, usando el paquete *re* y su función *findall* se encuentran todos los números existentes en el nombre.\n",
    "Continúa cargando la imagen y comenzando el procesado:\n",
    "\n",
    "* Aumento del contraste\n",
    "* Conversión a escala de grises\n",
    "* Binarización\n",
    "* Redimensionado \n",
    "* Normalización entre 0 y 1\n",
    "\n",
    "Se extraen los valores del eje izquierdo y derecho y comienza el \"muestreo\" de la imagen.\n",
    "\n",
    "Esta operación puede llevar unos minutos de cómputo, dependiendo del número de imágenes y el tamaño final deseado. En un equipo de 8 núcleos y 16 hilos y 16GB de memoria RAM tarda aproximadamente menos de un minuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a5b678",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imagenes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-05e16517e032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimagen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimagenes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mvaloresSalida\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'-?\\d+\\.?\\d*'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcontrast_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgray_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrast_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imagenes' is not defined"
     ]
    }
   ],
   "source": [
    "    for imagen in imagenes:\n",
    "        valoresSalida = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', imagen.name)]\n",
    "        img = cv2.imread(dir + '/' + imagen.name)\n",
    "        contrast_img = cv2.addWeighted(img, 2.3, np.zeros(img.shape, img.dtype), 0, 0)\n",
    "        gray_img = cv2.cvtColor(contrast_img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh1 = cv2.threshold(gray_img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "        imagen_re = cv2.resize(thresh1, (24, 18))\n",
    "        final_img = imagen_re / 255\n",
    "        valores[indice_x, indice_y] = valoresSalida[7]\n",
    "        valores[indice_x, indice_y + 1] = valoresSalida[9]\n",
    "        for i in range(final_img.shape[0]):\n",
    "            for j in range(final_img.shape[1]):\n",
    "                valores[indice_x, indice_y + 2] = final_img[i, j]\n",
    "                indice_y = indice_y + 1\n",
    "        indice_x = indice_x + 1\n",
    "        indice_y = 0\n",
    "\n",
    "    valores = np.round(valores, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b01f7",
   "metadata": {},
   "source": [
    "El resultado de aplicar los dintintos procesamientos se muestran a continuación:\n",
    "\n",
    "#### Cargar imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be901fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('imagen_2021-02-16 14_47_49.661111_EjeIzda1_-0.762908935546875_EjeDcha4_-0.979400634765625.jpg')\n",
    "cv2.imshow('Imagen Original', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa2077",
   "metadata": {},
   "source": [
    "#### Aumento del contraste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb90e9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast_img = cv2.addWeighted(img, 2.3, np.zeros(img.shape, img.dtype), 0, 0)\n",
    "cv2.imshow('Imagen Contrastada', contrast_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed0a1e",
   "metadata": {},
   "source": [
    "#### Conversión a escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca84ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img = cv2.cvtColor(contrast_img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Imagen en Gris', gray_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11615f",
   "metadata": {},
   "source": [
    "#### Binarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8987971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret, thresh1 = cv2.threshold(gray_img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Imagen Binarizada', thresh1)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4602d1ea",
   "metadata": {},
   "source": [
    "#### Redimensionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7d40826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_img = cv2.resize(thresh1, (24, 18))\n",
    "cv2.imshow('Imagen Redimensionada', resize_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c22d91",
   "metadata": {},
   "source": [
    "Para finalizar, guardamos el array con los valores capturados en formato *csv* para poder usarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data.csv', valores, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e3ac51",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "En la sección anterior se ha creado un dataset listo para ser usado por una red neuronal. En esta, se verá la creacion de la misma, los resultados obtenidos y el por qué de las decisiones tomadas.\n",
    "Se ha decidido usar una Red Neuronal Artificial (ANN), más concretamente una Multilayer Perceptron (MLP) por su gran desempeño y facilidad de creación.\n",
    "Dado que no son valores discretos, como podría ser la pertenencia a una clase o etiqueta, sino que son valores continuos, estamos ante un problema de regresión. El fin de la red será dado un vector, ser capaz de entregar de la manera más fiel posible los valores que un piloto usaría con el mando ante esa misma situación. Se obtendrán valores entre 0 y -1, aunque no se tratan de límites estrictos.\n",
    "Para ello, se ha usado la librería *tensorflow* que incluye *keras*. Más adelante se comentará con mayor detalle.\n",
    "\n",
    "### Desarrollo del código\n",
    "\n",
    "En un fichero llamado \"entrenar.py\" se ha diseñado la red. Comenzamos importando todas las funciones necesarias, estas son:\n",
    "\n",
    "* Sequential: Agrupa una pila de capas a un modelo\n",
    "\n",
    "* Dense: Capa de neuronas\n",
    "\n",
    "* Dropout: Desactiva un tanto por ciento de neuronas\n",
    "\n",
    "* Adam: Optimizador del modelo\n",
    "\n",
    "* train_test_split: Divide un dataset aleatoriamente en conjunto de entrenamiento y conjunto de test\n",
    "\n",
    "* EarlyStopping: Para automáticamente cuando no se mejora el error de validación\n",
    "\n",
    "* mean_squared_error: Usado para calcular el error entre el conjunto de test y las predicciones del modelo\n",
    "\n",
    "Usando el dataset generado en la sección anterior, cargamos los valores que se van a trabajar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataframe = read_csv(\"data.csv\", header=None, sep=',')\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218a8f6",
   "metadata": {},
   "source": [
    "El dataset cargado se divide en en valores de entrada \"X\" y valores de salida \"Y\". A su vez, estos dataset se dividen usando la función anteriormente mencionada, creando un conjunto de entrenamiento del 80% de las muestras, dejando un 10% para el conjunto de validación y otro 10% para el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ea8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, 2:]\n",
    "Y = dataset[:,0:2]\n",
    "\n",
    "lr = 0.001\n",
    "filas_entrada = dataset.shape[0]\n",
    "columnas_entrada = dataset.shape[1]-2\n",
    "batch_size = 32\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33dc35e",
   "metadata": {},
   "source": [
    "Siguiendo con lo anterior, se puede dar comienzo al diseño de la red neuronal. Para ello, creamos un objeto tipo *Sequential*, que será el plano donde se añadirán las capas de neuronas.\n",
    "Será una red de 3 capas, una capa de entrada y 2 capas ocultas, por lo que se puede considerar una red profunda. Este es el diseño que mejor resultado ha obtenido para este trabajo.\n",
    "Continuamos añadiendo la primer capa densa, con tantas neuronas como características de entrada (de aquí la importancia de contar con un buen procesado de datos), con una función de activación tipo \"relu\". A esta capa le añadiremos un *Dropout* del 40%.\n",
    "Agregamos la primera capa oculta, con un tercio de neuronas que la capa de entrada, cuya función de activacion es la misma, al igual que el *Dropout*.\n",
    "La segunda capa oculta cuenta con un quinto de neuronas que la capa de entrada, manteniendo la función de activacion y bajando la probabilidad del *Dropout* al 30%.\n",
    "Terminamos el diseño con la capa de salida, que consta de 2 neuronas ya que son necesarios dos valores para el funcionamiento del vehiculo. Dado que se trata de un problema de regresión, la función de activación de la capa de salida debe ser lineal.\n",
    "Nótese que lo que se busca con este diseño es un embotellamiento, comenzando por una mayor cantidad de neuronas para ir reduciendo el número capa a capa. Dado que son capas densas, están interconectadas entre ellas, o dicho de otra manera, es una red full conected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd51f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = Sequential()\n",
    "\n",
    "red.add(Dense(units=columnas_entrada, activation='relu'))\n",
    "red.add(Dropout(0.4))\n",
    "\n",
    "red.add(Dense(units=int(columnas_entrada/3), activation='relu'))\n",
    "red.add(Dropout(0.4))\n",
    "\n",
    "red.add(Dense(units=int(columnas_entrada/5), activation='relu'))\n",
    "red.add(Dropout(0.3))\n",
    "\n",
    "red.add(Dense(units=2, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6969cb7",
   "metadata": {},
   "source": [
    "Una vez diseñada la red, debemos definir qué se quiere medir, cómo se va a mejorar y qué medida juzgará el desempeño.\n",
    "Dado que es un problema de regresión, las pérdidas se mediran con el error cuadrático medio o mse, se optimizará o actualizará el valor de los pesos con *Adam* y observaremos la evolución del error cuadrático medio.\n",
    "También iniciamos el *EarlyStopping*, simplemente indicando cuantas épocas deben pasar sin mejoría para detener el entrenamiento. Además, le indicamos que una vez finalizado el entrenamiento, recupere la mejor configuración que haya sido capaz de encontrar. Puede parecer que el número de épocas sin mejoría es alto, pero se ha indicado un learning rate bajo, por lo que los pesos variarán lentamente. De esta manera se asegura un resultado competitivo.\n",
    "Por último, comienza el entrenamiento. Será necesario indicar el conjunto de entrenamiento de entrada con sus salidas correspondientes, un batch_size de 32 muestras, los datos para la validación, creados anteriormente y un callback, donde añadiremos el *EarlyStopping*.\n",
    "\n",
    "Esta operación puede llevar tiempo de procesamiento, dependiendo de la capacidad de la máquina usada, el tamaño de los datos, el batch_size, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "red.compile(loss='mean_squared_error', optimizer=Adam(lr=lr), \n",
    "            metrics=['MeanSquaredError'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=200, restore_best_weights=True)\n",
    "\n",
    "resultado = red.fit(x=X_train, y=Y_train, batch_size=batch_size,\n",
    "            epochs=10000, validation_data=(X_val, Y_val),\n",
    "            verbose=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cd5bc",
   "metadata": {},
   "source": [
    "A modo de comprobación, se puede mostrar el mejor valor del error de validación, el que podemos comparar con el error que se genera entre la predicción y el conjunto de test. En la gran mayoria de casos, este segundo error debe ser mínimamente mayor que el error de validación, lo que nos indica que es capaz de predecir correctamente. Se generan dos gráficas pertenecientes a la evolución de las pérdidas de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(resultado.history['val_loss']))\n",
    "\n",
    "Y_pred = red.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "\n",
    "print(mse)\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(resultado.history['loss'], label=\"train_loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.figure()\n",
    "plt.plot(resultado.history['val_loss'], label=\"val_loss\")\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf77f00",
   "metadata": {},
   "source": [
    "Para finalizar esta sección, creamos un directorio donde guardar la configuración calculada por la red y guardamos tanto el modelo como los pesos, que usaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'modelo'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "red.save('modelo/modelo.h5')\n",
    "red.save_weights('modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfa9e0",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Antes de probar estos resultados en el vehiculo, se va a simular el comportamiento del modelo entrenado. \n",
    "Para ello, se creará una funcion que realice el preprocesado de la imagen, y con una imagen que no se haya usado para el entrenamiento, se probará.\n",
    "Se carga el modelo y sus pesos correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92a161e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import re\n",
    "\n",
    "modelo = 'modelo.h5'\n",
    "pesos = 'pesos.h5'\n",
    "red = load_model(modelo)\n",
    "red.load_weights(pesos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c76e3c",
   "metadata": {},
   "source": [
    "La función *predict* será la encargada de dicha tarea. Es el mismo procesado que sufren las imágenes para generar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "060f761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(file):\n",
    "    indice = 0\n",
    "    valoresSalida = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', file)]\n",
    "    img = cv2.imread(file)\n",
    "    valores = np.empty((1, 24*18))\n",
    "    contrast_img = cv2.addWeighted(img, 2.3, np.zeros(img.shape, img.dtype), 0, 0)\n",
    "    gray_img = cv2.cvtColor(contrast_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh1 = cv2.threshold(gray_img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    resize_img = cv2.resize(thresh1, (24, 18))\n",
    "    final_img = resize_img / 255\n",
    "    for i in range(final_img.shape[0]):\n",
    "        for j in range(final_img.shape[1]):\n",
    "            valores[0, indice] = final_img[int(i), int(j)]\n",
    "            indice = indice + 1\n",
    "\n",
    "\n",
    "    respuesta = red.predict(valores)\n",
    "    print('Eje izquierdo real: ',valoresSalida[7], \n",
    "          ', Eje derecho real: ', valoresSalida[9])\n",
    "    print('Eje izquierdo predicho: ',respuesta[0,0], \n",
    "          ', Eje derecho predicho: ', respuesta[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e8773",
   "metadata": {},
   "source": [
    "Hacemos uso de la función, y como se puede ver, el error entre ambos valores es mínimo, por lo que se puede esperar que el funcionamiento del vehiculo en las pruebas sea satisfactoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b44f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eje izquierdo real:  -0.762908935546875 , Eje derecho real:  -0.979400634765625\n",
      "Eje izquierdo predicho:  -0.7943145 , Eje derecho predicho:  -1.0023944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.7943145, -1.0023944]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('imagen_2021-02-16 14_47_49.661111_EjeIzda1_-0.762908935546875_EjeDcha4_-0.979400634765625.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb1e32",
   "metadata": {},
   "source": [
    "# Prueba en el vehiculo\n",
    "\n",
    "Ahora que hemos comprobado que el regresor funciona correctamente, podemos cargarlo en el vehiculo y comenzar las pruebas reales.\n",
    "En primer lugar cargamos los paquetes necesarios, el modelo y los pesos calculados en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RPi.GPIO as GPIO\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Cargamos el modelo y los pesos de la red\n",
    "modelo = 'modelo.h5'\n",
    "pesos = 'pesos.h5'\n",
    "\n",
    "red = load_model(modelo)\n",
    "red.load_weights(pesos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df101ced",
   "metadata": {},
   "source": [
    "Configuramos los pines del puerto GPIO de la Raspberry Pi, describiendolos como salidas que proporcionarán un pulso PWM a los motores para así regular la velocidad. Hacemos esto para el eje derecho e izquierdo. Finalmente, comenzamos a capturar imagenes con la cámara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ebd7b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPIO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-848dc4073983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdirectionLeft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m37\u001b[0m \u001b[1;31m#Conectar a D7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mGPIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#disable warnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mGPIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGPIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBOARD\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#set pin numbering system # Referencia a la posición física.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GPIO' is not defined"
     ]
    }
   ],
   "source": [
    "directionRight = 31 #Conectar a D4\n",
    "speedRight = 33 # PWM pin connected Right motor #Conectar a M1 -> D5\n",
    "speedLeft = 35 # PWM pin connected Left motor #Conectar a M2 -> D6\n",
    "directionLeft = 37 #Conectar a D7\n",
    "\n",
    "GPIO.setwarnings(False) #disable warnings\n",
    "GPIO.setmode(GPIO.BOARD) #set pin numbering system # Referencia a la posición física.\n",
    "\n",
    "GPIO.setup(directionLeft,GPIO.OUT)\n",
    "GPIO.setup(directionRight,GPIO.OUT)\n",
    "\n",
    "GPIO.setup(speedLeft,GPIO.OUT)\n",
    "pwmLeft = GPIO.PWM(speedLeft,100) #create PWM instance with frequency #En el código de ejemplo usa 1000, pero no me va bien.\n",
    "pwmLeft.start(0) #start PWM of required Duty Cycle\n",
    "\n",
    "GPIO.setup(speedRight,GPIO.OUT)\n",
    "pwmRight = GPIO.PWM(speedRight,100) #create PWM instance with frequency\n",
    "pwmRight.start(0) #start PWM of required Duty Cycle\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f0418",
   "metadata": {},
   "source": [
    "Entramos en un bucle infinito, pues el coche no para de moverse hasta que sea interrumpido. Leemos la imagen capturada y se le aplica el procesado explicado anteriormente. Extraemos los valores de la predicción y comprobamos su polaridad. Si el resultado es mayor que cero significa que las ruedas deberán girar en sentido contrario, es decir, marcha atras. Por otro lado, si es menos que cero, girarán en el sentido de la circulación.\n",
    "Para regular la potencia, definimos la variable *pot* que ocupará un valor entre 0 y 100. Este valor, multiplicado con la salida de la red indicará el tamaño del pulso PWM, en otras palabras, el tiempo que estará encendido el motor en un ciclo del pulso.\n",
    "Para terminar, liberamos la cámara cuando se detenga el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "while (True):\n",
    "    ret, img = cam.read()\n",
    "    indice = 0\n",
    "    valores = np.empty((1, 24*18))\n",
    "    contrast_img = cv2.addWeighted(img, 2.3, np.zeros(img.shape, img.dtype), 0, 0)\n",
    "    gray_img = cv2.cvtColor(contrast_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray_img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    resize_img = cv2.resize(thresh, (24,18))\n",
    "    final_img = resize_img / 255\n",
    "    \n",
    "    for i in range(final_img.shape[0]):\n",
    "        for j in range(final_img.shape[1]):\n",
    "            valores[0, indice] = final_img[i, j]\n",
    "            indice = indice + 1\n",
    "            \n",
    "    output = red.predict(valores)\n",
    "    Eje_izq = output[0,0]\n",
    "    Eje_dch = output[0,1]\n",
    "    \n",
    "    if Eje_izq < 0:\n",
    "        GPIO.output(directionLeft, True)\n",
    "    else:\n",
    "        GPIO.output(directionLeft, False)\n",
    "        \n",
    "    if Eje_dch < 0:\n",
    "        GPIO.output(directionRight, True)\n",
    "    else:\n",
    "        GPIO.output(directionRight, False)\n",
    "        \n",
    "    pot = 50 # JK pot = 100 va a toda velocidad. \n",
    "    pwmRight.ChangeDutyCycle(int (abs(Eje_dch)*pot))\n",
    "    pwmLeft.ChangeDutyCycle(int (abs(Eje_izq)*pot))    \n",
    "\n",
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
